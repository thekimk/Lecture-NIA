{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b29406-5f27-4bb7-97d2-65e2fb19a9bf",
   "metadata": {
    "id": "51b29406-5f27-4bb7-97d2-65e2fb19a9bf"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E7Dh7n2rtc7J",
   "metadata": {
    "collapsed": true,
    "id": "E7Dh7n2rtc7J",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브 연결\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 라이브러리 설치\n",
    "!pip install --upgrade --no-cache-dir numpy seaborn\n",
    "!pip install ydata_profiling\n",
    "!pip install missingno\n",
    "!pip install tqdm\n",
    "\n",
    "!pip install -U kss==5.2.0\n",
    "!pip install kiwipiepy\n",
    "!pip install soynlp\n",
    "!pip install keybert\n",
    "!pip install keybert[gensim]\n",
    "!pip install sentence_transformers\n",
    "\n",
    "!pip install nltk\n",
    "!pip install konlpy\n",
    "!pip install gensim\n",
    "!pip install bertopic -U\n",
    "!pip install bertopic[visualization] -U\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n",
    "!pip install datasets\n",
    "\n",
    "!pip install catboost\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LhvzaX-IpBhP",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T13:53:26.321951Z",
     "iopub.status.busy": "2025-04-06T13:53:26.321115Z",
     "iopub.status.idle": "2025-04-06T13:53:33.882805Z",
     "shell.execute_reply": "2025-04-06T13:53:33.881580Z",
     "shell.execute_reply.started": "2025-04-06T13:53:26.321904Z"
    },
    "id": "LhvzaX-IpBhP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "E: 잠금 파일 /var/lib/apt/lists/lock 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: /var/lib/apt/lists/ 디렉터리를 잠글 수 없습니다\n",
      "W: /var/cache/apt/pkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "W: /var/cache/apt/srcpkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "E: 잠금 파일 /var/lib/dpkg/lock-frontend 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 22:53:28.866694: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 22:53:28.879100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743947608.894154    2080 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743947608.899070    2080 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-06 22:53:28.917270: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to /home/kk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Auto reload of library\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System related and data input controls\n",
    "import os\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "## 한글 폰트 설치\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum* -qq\n",
    "## NanumGothic 폰트 경로 지정\n",
    "fm.fontManager.addfont('/usr/share/fonts/truetype/nanum/NanumGothic.ttf')\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "## 한글 폰트 설정\n",
    "matplotlib.rcParams['font.family'] = font_prop.get_name()\n",
    "plt.rc('font', family='NanumGothic')\n",
    "sns.set(font=font_prop.get_name())\n",
    "## 마이너스 표시 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Understanding of Data\n",
    "from ydata_profiling import ProfileReport\n",
    "import missingno as msno\n",
    "\n",
    "# Custom\n",
    "## 사용자의 실제 작업경로로 설정!\n",
    "# os.chdir('/content/drive/MyDrive/Research/Analysis/Lecture/특강_20250412_한국지능정보사회진흥원_빅데이터센터')\n",
    "# !ls\n",
    "from module_KK import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CkFjttZ5EBSp",
   "metadata": {
    "id": "CkFjttZ5EBSp"
   },
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NWc9zp9jEBIG",
   "metadata": {
    "id": "NWc9zp9jEBIG"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "file_location = os.path.join(os.path.join('.', 'Data', 'df_concat_BA1.csv'))\n",
    "Y_colname = '기부여부'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 123\n",
    "SAMPLING_METHOD = 'RandomUnderSampler'\n",
    "SAMPLING_STRATEGY = 'auto'\n",
    "SCALER = MinMaxScaler()\n",
    "LABEL_LIST = ['Non-donation', 'Donation']\n",
    "\n",
    "# Modeling AI\n",
    "OUTPUT_TYPE = 'logit'\n",
    "MAX_DISPLAY = 30\n",
    "DEPENDENCY = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uPcYYHXbE2Ia",
   "metadata": {
    "id": "uPcYYHXbE2Ia"
   },
   "source": [
    "# BA Process Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rTrihOpvE-sa",
   "metadata": {
    "id": "rTrihOpvE-sa"
   },
   "outputs": [],
   "source": [
    "# 데이터분석 프로세스\n",
    "## 데이터 로딩\n",
    "df = pd.read_csv(file_location, encoding='utf-8-sig')\n",
    "## 데이터 전처리\n",
    "X_train, X_test, Y_train, Y_test, df_prep = preprocessing_MDIS_KK(df)\n",
    "X_colname = [col for col in df_prep.columns if col != Y_colname]\n",
    "## 결과 확인\n",
    "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
    "print(X_test.shape, Y_test.shape, X_test.min(), X_test.max())\n",
    "print('Complete!')\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept=True, class_weight='balanced')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Explanation\n",
    "explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "                    MAX_DISPLAY=MAX_DISPLAY, model_type='linear',\n",
    "                    link=OUTPUT_TYPE, sample_size=1,\n",
    "                    sample_size_1000=1000,\n",
    "                    plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jb1XKJVBSNRz",
   "metadata": {
    "id": "Jb1XKJVBSNRz"
   },
   "source": [
    "# Prediction Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I4IGg3tzFeSL",
   "metadata": {
    "id": "I4IGg3tzFeSL"
   },
   "outputs": [],
   "source": [
    "# 데이터분석 프로세스\n",
    "## 데이터 로딩\n",
    "df = pd.read_csv(file_location, encoding='utf-8-sig')\n",
    "## 데이터 전처리\n",
    "X_train, X_test, Y_train, Y_test, df_prep = preprocessing_MDIS_KK(df)\n",
    "X_colname = [col for col in df_prep.columns if col != Y_colname]\n",
    "## 결과 확인\n",
    "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
    "print(X_test.shape, Y_test.shape, X_test.min(), X_test.max())\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4jsCeKGWzzvD",
   "metadata": {
    "id": "4jsCeKGWzzvD"
   },
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i8mNI5ocQEBr",
   "metadata": {
    "id": "i8mNI5ocQEBr"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept=True, class_weight='balanced')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='linear',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GDQ3hSdC2_Pd",
   "metadata": {
    "id": "GDQ3hSdC2_Pd"
   },
   "source": [
    "## 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utxqwPwCXZfL",
   "metadata": {
    "id": "utxqwPwCXZfL"
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100,\n",
    "                               class_weight='balanced',   # 'balanced_subsample'\n",
    "                               random_state=123)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fYMgyKsu-DIv",
   "metadata": {
    "id": "fYMgyKsu-DIv"
   },
   "source": [
    "## 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wL6R1FB893Kh",
   "metadata": {
    "id": "wL6R1FB893Kh"
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model = XGBClassifier(n_estimators=100,\n",
    "                      scale_pos_weight=Y_train.value_counts()[0]/Y_train.value_counts()[1],   # binary\n",
    "                      random_state=123)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2jAK0Za_OZP",
   "metadata": {
    "id": "d2jAK0Za_OZP"
   },
   "source": [
    "## 4) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t3TBr54z93IY",
   "metadata": {
    "id": "t3TBr54z93IY"
   },
   "outputs": [],
   "source": [
    "# LGBM\n",
    "model = LGBMClassifier(n_estimators=100,\n",
    "                       class_weight='balanced',\n",
    "                       random_state=123)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tD07tBmL_hBC",
   "metadata": {
    "id": "tD07tBmL_hBC"
   },
   "source": [
    "## 5) CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kfyUInTJ93Fl",
   "metadata": {
    "id": "kfyUInTJ93Fl"
   },
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "model = CatBoostClassifier(n_estimators=100,\n",
    "                           auto_class_weights='Balanced',\n",
    "                           allow_writing_files=False,\n",
    "                           random_state=123)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vjxDN2Q__ten",
   "metadata": {
    "id": "vjxDN2Q__ten"
   },
   "source": [
    "## 6) MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VcRsvbMO93Cy",
   "metadata": {
    "id": "VcRsvbMO93Cy"
   },
   "outputs": [],
   "source": [
    "# MLP\n",
    "## reshape\n",
    "if WEIGHT_METHOD != None:\n",
    "    Y_train_dl, Y_test_dl = reshape_YtoOneHot(Y_train, Y_test)\n",
    "else:\n",
    "    Y_train_dl, Y_test_dl = Y_train.copy(), Y_test.copy()\n",
    "X_train_dl, X_test_dl = X_train.copy(), X_test.copy()\n",
    "\n",
    "## 모델링\n",
    "ALGO_NAME='MLP'\n",
    "model = modeling_MLP(X_train_dl, Y_train_dl,\n",
    "                     node_MLP=NODE_MLP,\n",
    "                     HIDDEN_ACTIVATION=HIDDEN_ACTIVATION, OUTPUT_ACTIVATION=OUTPUT_ACTIVATION,\n",
    "                     REGULARIZER=REGULARIZER, DROPOUT_RATIO=DROPOUT_RATIO,\n",
    "                     LOSS=LOSS, OPTIMIZER=OPTIMIZER, LEARNING_RATE=LEARNING_RATE)\n",
    "model, FILENAME = learning(model, X_train_dl, X_test_dl, Y_train_dl,\n",
    "                           WEIGHT_METHOD=WEIGHT_METHOD,\n",
    "                           VALIDATION_SPLIT=VALIDATION_SPLIT, VALIDATION_DATA=VALIDATION_DATA,\n",
    "                           BATCH_SIZE=BATCH_SIZE, EPOCHS=EPOCHS, VERBOSE=VERBOSE,\n",
    "                           MONITOR=MONITOR, MONITOR_MODE=MONITOR_MODE, EARLYSTOP_PATIENT=EARLYSTOP_PATIENT,\n",
    "                           shap=False, X_colname=X_colname, X_top_display=X_TOP_DISPLAY)\n",
    "Score_te_mlp, Score_trte_mlp = prediction_class(model, X_train_dl, Y_train_dl, X_test_dl, Y_test_dl,\n",
    "                                                LABEL_LIST=LABEL_LIST, ALGO_NAME=ALGO_NAME)\n",
    "display(Score_te_mlp, Score_trte_mlp)\n",
    "\n",
    "## 베스트 모델 로딩\n",
    "model_mlp = load_model(FILENAME)\n",
    "Score_te_mlp, Score_trte_mlp = prediction_class(model, X_train_dl, Y_train_dl, X_test_dl, Y_test_dl,\n",
    "                                                LABEL_LIST=LABEL_LIST, ALGO_NAME=ALGO_NAME)\n",
    "display(model_mlp, Score_te_mlp, Score_trte_mlp)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F_R1XMm7_voM",
   "metadata": {
    "id": "F_R1XMm7_voM"
   },
   "source": [
    "## 7) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DxJDfwZ492_4",
   "metadata": {
    "id": "DxJDfwZ492_4"
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "## reshape\n",
    "if WEIGHT_METHOD != None:\n",
    "    Y_train_dl, Y_test_dl = reshape_YtoOneHot(Y_train, Y_test)\n",
    "else:\n",
    "    Y_train_dl, Y_test_dl = Y_train.copy(), Y_test.copy()\n",
    "X_train_dl, X_test_dl = reshape_X2Dto3D(X_train, X_test)\n",
    "\n",
    "## 모델링\n",
    "ALGO_NAME='CNN'\n",
    "model = modeling_CNN1D(X_train_dl, Y_train_dl,\n",
    "                       node_CNN1=NODE_CNN1,\n",
    "                       node_CNN2=NODE_CNN2,\n",
    "                       HIDDEN_ACTIVATION=HIDDEN_ACTIVATION, OUTPUT_ACTIVATION=OUTPUT_ACTIVATION,\n",
    "                       KERNEL_SIZE=KERNEL_SIZE, STRIDE=STRIDE, PADDING=PADDING,\n",
    "                       POOL_SIZE=POOL_SIZE, POOL_STRIDE=POOL_STRIDE,\n",
    "                       REGULARIZER=REGULARIZER, DROPOUT_RATIO=DROPOUT_RATIO,\n",
    "                       LOSS=LOSS, OPTIMIZER=OPTIMIZER, LEARNING_RATE=LEARNING_RATE)\n",
    "model, FILENAME = learning(model, X_train_dl, X_test_dl, Y_train_dl,\n",
    "                           WEIGHT_METHOD=WEIGHT_METHOD,\n",
    "                           VALIDATION_SPLIT=VALIDATION_SPLIT, VALIDATION_DATA=VALIDATION_DATA,\n",
    "                           BATCH_SIZE=BATCH_SIZE, EPOCHS=EPOCHS, VERBOSE=VERBOSE,\n",
    "                           MONITOR=MONITOR, MONITOR_MODE=MONITOR_MODE, EARLYSTOP_PATIENT=EARLYSTOP_PATIENT,\n",
    "                           shap=False, X_colname=X_colname, X_top_display=X_TOP_DISPLAY)\n",
    "Score_te_cnn, Score_trte_cnn = prediction_class(model, X_train_dl, Y_train_dl, X_test_dl, Y_test_dl,\n",
    "                                                LABEL_LIST=LABEL_LIST, ALGO_NAME=ALGO_NAME)\n",
    "display(Score_te_cnn, Score_trte_cnn)\n",
    "\n",
    "## 베스트 모델 로딩\n",
    "model_mlp = load_model(FILENAME)\n",
    "Score_te_mlp, Score_trte_mlp = prediction_class(model, X_train_dl, Y_train_dl, X_test_dl, Y_test_dl,\n",
    "                                                LABEL_LIST=LABEL_LIST, ALGO_NAME=ALGO_NAME)\n",
    "display(model_mlp, Score_te_mlp, Score_trte_mlp)\n",
    "\n",
    "# # Explanation\n",
    "# explanation_SHAP_KK(model, X_train, X_test, X_colname,\n",
    "#                     MAX_DISPLAY=MAX_DISPLAY, model_type='tree',\n",
    "#                     link=OUTPUT_TYPE, sample_size=1,\n",
    "#                     sample_size_1000=1000,\n",
    "#                     plot_interaction=True)\n",
    "\n",
    "# Prediction\n",
    "P_trpred = pd.DataFrame(model.predict_proba(X_train)[:,-1],\n",
    "                        index=Y_train.index, columns=['Pred'])\n",
    "P_tepred = pd.DataFrame(model.predict_proba(X_test)[:,-1],\n",
    "                        index=Y_test.index, columns=['Pred'])\n",
    "Y_trpred = (P_trpred >= 0.5).astype(int)\n",
    "Y_tepred = (P_tepred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "Score_te, Score_trte = prediction_class(model, X_train, Y_train, X_test, Y_test,\n",
    "                                        LABEL_LIST=LABEL_LIST, ALGO_NAME='Logistic')\n",
    "display(Score_te, Score_trte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H7QsVxl1AP_G",
   "metadata": {
    "id": "H7QsVxl1AP_G"
   },
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sS6jrEx9928k",
   "metadata": {
    "id": "sS6jrEx9928k"
   },
   "outputs": [],
   "source": [
    "folder_location = os.path.join(os.getcwd(),'Result')\n",
    "prediction_summary(folder_location=folder_location,\n",
    "                   algonames=['Logistic Regression', 'Random Forest', 'XGBoost', 'LGBM', 'CatBoost', 'MLP', 'CNN'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n5NjkdcC939f",
   "metadata": {
    "id": "n5NjkdcC939f"
   },
   "source": [
    "# Feature Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lB8u46IdHzKu",
   "metadata": {
    "id": "lB8u46IdHzKu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HfQ8Eomk92oF",
   "metadata": {
    "id": "HfQ8Eomk92oF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lAYcffNK92X7",
   "metadata": {
    "id": "lAYcffNK92X7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py312_cuda126dnn960",
   "language": "python",
   "name": "py312_cuda126dnn960"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
